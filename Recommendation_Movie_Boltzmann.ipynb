{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1rFPxBK5yU3O",
        "outputId": "7c70c50a-5c21-4245-a5a8-ebfbdcb7221c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "#lets import drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#lets import the necessary libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.parallel\n",
        "import torch.optim as optim\n",
        "import torch.utils.data\n",
        "from torch.autograd import Variable"
      ],
      "metadata": {
        "id": "pQisCzYfyisM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#lets import the dataset\n",
        "movies=pd.read_csv('/content/drive/MyDrive/Movie_Recommendation/ml-1m/movies.dat',sep='::',engine='python',encoding='latin-1',header=None)\n",
        "users=pd.read_csv('/content/drive/MyDrive/Movie_Recommendation/ml-1m/users.dat',sep='::',engine='python',encoding='latin-1',header=None)\n",
        "ratings=pd.read_csv('/content/drive/MyDrive/Movie_Recommendation/ml-1m/ratings.dat',sep='::',engine='python',encoding='latin-1',header=None)"
      ],
      "metadata": {
        "id": "jpT-4qTGzJbV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#lets import training and testing dataset\n",
        "training_set=pd.read_csv('/content/drive/MyDrive/Movie_Recommendation/ml-100k/u1.base',delimiter='\\t')\n",
        "testing_set=pd.read_csv('/content/drive/MyDrive/Movie_Recommendation/ml-100k/u1.test',delimiter='\\t')"
      ],
      "metadata": {
        "id": "NLLtdNTfz-7l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_set=np.array(training_set,dtype='int')\n",
        "testing_set=np.array(testing_set,dtype='int')\n"
      ],
      "metadata": {
        "id": "5w-Z5Dq80anc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#to find the number of users and movies\n",
        "nb_users=int(max(max(training_set[:,0]),max(testing_set[:,0])))\n",
        "nb_movies=int(max(max(training_set[:,1]),max(testing_set[:,0])))\n"
      ],
      "metadata": {
        "id": "N5mv3mpu0l3i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nb_users"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aoJncMWl1Ebl",
        "outputId": "47e8846e-e325-41d7-e04a-7701627371f1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "943"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nb_movies"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zHgrg8931GBL",
        "outputId": "d3940924-a056-4e22-b8ff-0de78900abc7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1682"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#lets create a function\n",
        "def convert(data):\n",
        "  new_data=[]\n",
        "  for id_users in range(1,nb_users + 1):\n",
        "    id_movies=data[:,1][data[:,0] == id_users]\n",
        "    id_ratings=data[:,2][data[:,0] == id_users]\n",
        "    rat=np.zeros(nb_movies)\n",
        "    rat[id_movies-1]=id_ratings\n",
        "    new_data.append(list(rat))\n",
        "  return new_data\n"
      ],
      "metadata": {
        "id": "_fLMwamp1Hy8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_set=convert(training_set)\n",
        "testing_set=convert(testing_set)"
      ],
      "metadata": {
        "id": "qwzerYtg2A6k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#converting the data into torch tensors\n",
        "training_set=torch.FloatTensor(training_set)\n",
        "testing_set=torch.FloatTensor(testing_set)"
      ],
      "metadata": {
        "id": "spPzkdpD2F8z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#conver the ratings into binary form 1 for liked and 0 for not liked\n",
        "training_set[training_set==0]=-1\n",
        "training_set[training_set==1]=0\n",
        "training_set[training_set==2]=0\n",
        "training_set[training_set>=3]=1\n",
        "\n",
        "testing_set[testing_set==0]=-1\n",
        "testing_set[testing_set==1]=0\n",
        "testing_set[testing_set==2]=0\n",
        "testing_set[testing_set>=3]=1"
      ],
      "metadata": {
        "id": "ayXnTTK724n0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#lets initialize the RBM model\n",
        "class RBM():\n",
        "  def __init__(self, nv, nh):\n",
        "    self.W = torch.randn(nh, nv)\n",
        "    self.a = torch.randn(1, nh)\n",
        "    self.b = torch.randn(1, nv)\n",
        "\n",
        "  def sample_h(self, x):\n",
        "    ## assigning the weights to the neuron\n",
        "    wx = torch.mm(x, self.W.t())\n",
        "    ## creating an activation function wher we have weights along with hidden neurons\n",
        "    activation = wx + self.a.expand_as(wx)\n",
        "    # now we need to find the probability of activation of hidden neuron given visible note\n",
        "    p_h_given_v = torch.sigmoid(activation)\n",
        "    #for the activation of hidden neuron we need to provide the sampling also which is bernoulli sampling\n",
        "    return p_h_given_v, torch.bernoulli(p_h_given_v)\n",
        "\n",
        "  def sample_v(self, y):\n",
        "    ## assigning the weights to the neuron\n",
        "    wy = torch.mm(y, self.W)\n",
        "    ## creating an activation function wher we have weights along with visible neurons\n",
        "    activation = wy + self.b.expand_as(wy)\n",
        "    # now we need to find the probability of activation of visible neuron given hidden note\n",
        "    p_v_given_h = torch.sigmoid(activation)\n",
        "    #for the activation of visible neuron we need to provide the sampling also which is bernoulli sampling\n",
        "    return p_v_given_h, torch.bernoulli(p_v_given_h)\n",
        "\n",
        "  def train(self, v0, vk, ph0, phk):\n",
        "    self.W += (torch.mm(v0.t(), ph0) - torch.mm(vk.t(), phk)).t()\n",
        "    self.b += torch.sum((v0 - vk), 0)\n",
        "    self.a += torch.sum((ph0 - phk), 0)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ZxW_oaNb4ATh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#lets start training the RBM\n",
        "nv=len(training_set[0])\n",
        "nh=100\n",
        "batch_size=100\n",
        "rbm=RBM(nv,nh)"
      ],
      "metadata": {
        "id": "j2UU216W_zSz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#now lets start training our model\n",
        "nb_epoch=10\n",
        "for epoch in range(1,nb_epoch + 1):\n",
        "  train_loss=0\n",
        "  s=0.\n",
        "  for id_user in range(0,nb_users-batch_size,batch_size):\n",
        "    #lets take the input vector\n",
        "    vk=training_set[id_user:id_user+batch_size]\n",
        "    #lets take the target vector\n",
        "    v0=training_set[id_user:id_user+batch_size]\n",
        "    #lets take the initial probability of hidden node\n",
        "    ph0,_ =rbm.sample_h(v0)\n",
        "    #now lets start with gibbs sampling based on the number of epoches\n",
        "    for k in range(10):\n",
        "      #update the weights of the hidden node first\n",
        "      _,hk =rbm.sample_h(vk)\n",
        "      #now update the weigths of the visible node\n",
        "      _,vk=rbm.sample_v(hk)\n",
        "      #now remove the ratings which contain the value -1\n",
        "      vk[v0<0] = v0[v0<0]\n",
        "    #now find the probability after updating the weight\n",
        "    phk,_ =rbm.sample_h(vk)\n",
        "    #lets train the data\n",
        "    rbm.train(v0,vk,ph0,phk)\n",
        "    #the losses need to be normalised\n",
        "    train_loss+=torch.mean(torch.abs(v0[v0>=0]-vk[v0>=0]))\n",
        "    s+=1.\n",
        "\n",
        "  #lets print the number of epochs and losses for each epoch here trainloss/s for normalised value\n",
        "  print(f'epoch: {epoch} loss: {train_loss/s}')\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "SZjhio0M_5mT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0f9cbf57-7958-4d1d-d5d8-9fe3559f871e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 1 loss: 0.3574027419090271\n",
            "epoch: 2 loss: 0.2478228658437729\n",
            "epoch: 3 loss: 0.2501685619354248\n",
            "epoch: 4 loss: 0.24915796518325806\n",
            "epoch: 5 loss: 0.2499580681324005\n",
            "epoch: 6 loss: 0.2475331872701645\n",
            "epoch: 7 loss: 0.24922235310077667\n",
            "epoch: 8 loss: 0.24917981028556824\n",
            "epoch: 9 loss: 0.24557822942733765\n",
            "epoch: 10 loss: 0.24687665700912476\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Testing the RBM\n",
        "test_loss=0\n",
        "s=0.\n",
        "for id_user in range(nb_users):\n",
        "  #so here the v should be training set as this it the input so training data needed to activate neurons\n",
        "  v=training_set[id_user:id_user+1]\n",
        "  vt=testing_set[id_user:id_user+1]\n",
        "  if(len(vt[vt>=0]))>0:\n",
        "    _,h=rbm.sample_h(v)\n",
        "    _,v=rbm.sample_v(h)\n",
        "    test_loss += torch.mean(torch.abs(vt[vt>=0]-v[vt>=0]))\n",
        "    s += 1.\n",
        "print(f'test loss: {(test_loss/s)}')\n"
      ],
      "metadata": {
        "id": "PJpLIi9DIiB-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "20a12813-b9e2-4610-c472-7144d4622205"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test loss: 0.2466803789138794\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rXK_W9nAehKf"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}